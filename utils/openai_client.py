import json
import logging
import asyncio
import httpx
from datetime import datetime
from config import Config
from utils.helpers import count_tokens
from models.conversation_manager import ConversationManager, PromptType
from openai import AsyncOpenAI
from logger_config import logger

AUDIO_PHOTO_RESPOSE = "–ù–∞–ø–∏—à–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ —Ç–µ–∫—Å—Ç–æ–ºüôè \n–ù–∞—à —Å–æ—Ñ—Ç –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤–∏–¥–µ—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."

class OpenAIClient:
    
    _instance = None  
    
    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        transport = httpx.AsyncHTTPTransport(proxy=Config.PROXY_URL)
        http_async_client = httpx.AsyncClient(transport=transport)
        self._client = AsyncOpenAI(api_key=Config.OPENAI_API_KEY, http_client=http_async_client)
        self._conversation_manager = ConversationManager()
        self.model_gpt4omini = Config.MODEL_GPT4OMINI

    async def _ask_openai(self, messages, model):
        try:
            response = await self._client.chat.completions.create(
                temperature=Config.TEMPERATURE,
                model=model,
                messages=messages
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI: {e}")
            return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞.", 0, 0
        response_text = response.choices[0].message.content.strip()
        input_tokens, output_tokens = count_tokens(messages, response_text)
        # logger.info(f"–û—Ç–≤–µ—Ç –æ—Ç {model}: {response_text}")
        # logger.info(f"–í—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: {input_tokens}, –í—ã—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: {output_tokens}")
        return response_text, input_tokens, output_tokens
    
    async def create_gpt4o_response(self, question, chat_id):
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        # self._conversation_manager.add_user_message(chat_id, question)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—à–∞—Ç—å –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤
        self._conversation_manager.trim_history(chat_id, max_tokens=Config.MAX_TOKENS)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é –≤–º–µ—Å—Ç–µ —Å –Ω–æ–≤—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –¥–ª—è GPT
        task_response = asyncio.create_task(self._ask_openai(
            self._conversation_manager.get_history(chat_id),
            model=Config.MODEL_GPT4O
        ))
        task_delay = asyncio.create_task(asyncio.sleep(Config.ASSISTANT_DELAY))
        gpt4_response, input_tokens, output_tokens = await task_response
        await task_delay
        self._conversation_manager.add_assistant_message(chat_id, gpt4_response)
        
        return gpt4_response, input_tokens, output_tokens
    
    async def get_gpt4o_mini_response(self, chat_id, prompt_type: PromptType):
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—à–∞—Ç—å –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤
        self._conversation_manager.trim_history(chat_id, max_tokens=Config.MAX_TOKENS)
        
        history_for_mini = self._conversation_manager.get_history_for_mini(chat_id, prompt_type)
        logger.info("-------------------------")
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é –≤–º–µ—Å—Ç–µ —Å –Ω–æ–≤—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –¥–ª—è GPT
        task_response = asyncio.create_task(self._ask_openai(
            history_for_mini,
            model=Config.MODEL_GPT4OMINI
        ))
        gpt4_response, _, _ = await task_response
        logger.info("--get_gpt4o_mini response:")
        logger.info(gpt4_response)
        logger.info("-------------------------")
        
        return gpt4_response
